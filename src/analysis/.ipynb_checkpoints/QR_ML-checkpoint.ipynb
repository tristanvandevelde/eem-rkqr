{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7f15db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages (0.19.0)\n",
      "Requirement already satisfied: packaging in /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_addons) (21.3)\n",
      "Requirement already satisfied: typeguard>=2.7 in /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow_addons) (3.0.4)\n",
      "Collecting liquidSVM\n",
      "  Downloading liquidSVM-1.0.1.tar.gz (560 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m560.4/560.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages (from liquidSVM) (1.21.5)\n",
      "Building wheels for collected packages: liquidSVM\n",
      "  Building wheel for liquidSVM (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[118 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Using target:  native\n",
      "  \u001b[31m   \u001b[0m Using further args:  []\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/doc.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/__main__.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/covtype.1000.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/reg-1d.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-bc.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/reg-1d.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-bc.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-mc.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/covtype.1000.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-mc.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'liquidSVM' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-39/src\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/tristanvandevelde/opt/anaconda3/include -arch x86_64 -I/Users/tristanvandevelde/opt/anaconda3/include -fPIC -O2 -isystem /Users/tristanvandevelde/opt/anaconda3/include -arch x86_64 -I../.. -I../../bindings -Isrc -I/Users/tristanvandevelde/opt/anaconda3/include/python3.9 -c src/liquidSVMmodule.cpp -o build/temp.macosx-10.9-x86_64-cpython-39/src/liquidSVMmodule.o -O3 -std=c++0x -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DSYSTEM_WITH_64BIT\n",
      "  \u001b[31m   \u001b[0m In file included from src/liquidSVMmodule.cpp:37:\n",
      "  \u001b[31m   \u001b[0m In file included from src/common/liquidSVM.h:22:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/dataset.h:24:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.h:120:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.cpp:27:\n",
      "  \u001b[31m   \u001b[0m src/sources/shared/system_support/memory_allocation.h:46:10: warning: 'SYSTEM_WITH_64BIT' macro redefined [-Wmacro-redefined]\n",
      "  \u001b[31m   \u001b[0m         #define SYSTEM_WITH_64BIT\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m <command line>:2:9: note: previous definition is here\n",
      "  \u001b[31m   \u001b[0m #define SYSTEM_WITH_64BIT 1\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m In file included from src/liquidSVMmodule.cpp:37:\n",
      "  \u001b[31m   \u001b[0m In file included from src/common/liquidSVM.h:22:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/dataset.h:24:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.h:26:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:275:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__bit_reference:15:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/algorithm:653:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/functional:500:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__functional/function.h:20:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/shared_ptr.h:22:\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:9: warning: destructor called on non-final 'Tsvm_decision_function' that has virtual functions but non-virtual destructor [-Wdelete-non-abstract-non-virtual-dtor]\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator_traits.h:309:13: note: in instantiation of member function 'std::allocator<Tsvm_decision_function>::destroy' requested here\n",
      "  \u001b[31m   \u001b[0m         __a.destroy(__p);\n",
      "  \u001b[31m   \u001b[0m             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:450:25: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tsvm_decision_function>>::destroy<Tsvm_decision_function, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         __alloc_traits::destroy(__alloc(), _VSTD::__to_address(--__soon_to_be_end));\n",
      "  \u001b[31m   \u001b[0m                         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:374:29: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m     void clear() _NOEXCEPT {__destruct_at_end(__begin_);}\n",
      "  \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:487:9: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::clear' requested here\n",
      "  \u001b[31m   \u001b[0m         clear();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:519:5: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::~__vector_base' requested here\n",
      "  \u001b[31m   \u001b[0m     vector() _NOEXCEPT_(is_nothrow_default_constructible<allocator_type>::value)\n",
      "  \u001b[31m   \u001b[0m     ^\n",
      "  \u001b[31m   \u001b[0m src/sources/shared/decision_function/decision_function_manager.h:64:3: note: in instantiation of member function 'std::vector<Tsvm_decision_function>::vector' requested here\n",
      "  \u001b[31m   \u001b[0m                 Tdecision_function_manager();\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m src/sources/svm/decision_function/svm_decision_function_manager.cpp:54:33: note: in instantiation of member function 'Tdecision_function_manager<Tsvm_decision_function, Tsvm_train_val_info, Tsvm_test_info>::Tdecision_function_manager' requested here\n",
      "  \u001b[31m   \u001b[0m Tsvm_decision_function_manager::Tsvm_decision_function_manager()\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:15: note: qualify call to silence this warning\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:9: warning: destructor called on non-final 'Tsvm_solution' that has virtual functions but non-virtual destructor [-Wdelete-non-abstract-non-virtual-dtor]\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator_traits.h:309:13: note: in instantiation of member function 'std::allocator<Tsvm_solution>::destroy' requested here\n",
      "  \u001b[31m   \u001b[0m         __a.destroy(__p);\n",
      "  \u001b[31m   \u001b[0m             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:450:25: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tsvm_solution>>::destroy<Tsvm_solution, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         __alloc_traits::destroy(__alloc(), _VSTD::__to_address(--__soon_to_be_end));\n",
      "  \u001b[31m   \u001b[0m                         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:857:17: note: in instantiation of member function 'std::__vector_base<Tsvm_solution, std::allocator<Tsvm_solution>>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m         __base::__destruct_at_end(__new_last);\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1477:19: note: in instantiation of member function 'std::vector<Tsvm_solution>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m             this->__destruct_at_end(__m);\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1427:9: note: in instantiation of function template specialization 'std::vector<Tsvm_solution>::assign<Tsvm_solution *>' requested here\n",
      "  \u001b[31m   \u001b[0m         assign(__x.__begin_, __x.__end_);\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__algorithm/copy.h:35:19: note: (skipping 12 contexts in backtrace; use -ftemplate-backtrace-limit=0 to see all)\n",
      "  \u001b[31m   \u001b[0m         *__result = *__first;\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/memory:779:18: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tgrid<Tsvm_solution, Tsvm_train_val_info>>>::construct<Tgrid<Tsvm_solution, Tsvm_train_val_info>, const Tgrid<Tsvm_solution, Tsvm_train_val_info> &, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         _Traits::construct(__a, _VSTD::__to_address(__end2 - 1),\n",
      "  \u001b[31m   \u001b[0m                  ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:976:12: note: in instantiation of function template specialization 'std::__construct_backward_with_exception_guarantees<std::allocator<Tgrid<Tsvm_solution, Tsvm_train_val_info>>, Tgrid<Tsvm_solution, Tsvm_train_val_info> *>' requested here\n",
      "  \u001b[31m   \u001b[0m     _VSTD::__construct_backward_with_exception_guarantees(this->__alloc(), this->__begin_, this->__end_, __v.__begin_);\n",
      "  \u001b[31m   \u001b[0m            ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1117:9: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::__swap_out_circular_buffer' requested here\n",
      "  \u001b[31m   \u001b[0m         __swap_out_circular_buffer(__v);\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:2046:15: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::__append' requested here\n",
      "  \u001b[31m   \u001b[0m         this->__append(__sz - __cs);\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m src/sources/svm/training_validation/svm_manager.cpp:544:17: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::resize' requested here\n",
      "  \u001b[31m   \u001b[0m                 current_grids.resize(train_control.fold_control.number);\n",
      "  \u001b[31m   \u001b[0m                               ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:15: note: qualify call to silence this warning\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m 3 warnings generated.\n",
      "  \u001b[31m   \u001b[0m clang++ -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib -Wl,-rpath,/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib build/temp.macosx-10.9-x86_64-cpython-39/src/liquidSVMmodule.o -o build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM.cpython-39-darwin.so -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\n",
      "  \u001b[31m   \u001b[0m ld: library not found for -lstdc++\n",
      "  \u001b[31m   \u001b[0m clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for liquidSVM\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for liquidSVM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build liquidSVM\n",
      "Installing collected packages: liquidSVM\n",
      "  Running setup.py install for liquidSVM ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for liquidSVM\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[120 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Using target:  native\n",
      "  \u001b[31m   \u001b[0m Using further args:  []\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Users/tristanvandevelde/opt/anaconda3/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/doc.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/__main__.py -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/covtype.1000.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/reg-1d.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-bc.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/reg-1d.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-bc.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-mc.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/covtype.1000.train.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m copying liquidSVM/data/banana-mc.test.csv -> build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM/data\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'liquidSVM' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-10.9-x86_64-cpython-39/src\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/tristanvandevelde/opt/anaconda3/include -arch x86_64 -I/Users/tristanvandevelde/opt/anaconda3/include -fPIC -O2 -isystem /Users/tristanvandevelde/opt/anaconda3/include -arch x86_64 -I../.. -I../../bindings -Isrc -I/Users/tristanvandevelde/opt/anaconda3/include/python3.9 -c src/liquidSVMmodule.cpp -o build/temp.macosx-10.9-x86_64-cpython-39/src/liquidSVMmodule.o -O3 -std=c++0x -march=native -stdlib=libc++ -mmacosx-version-min=10.7 -DSYSTEM_WITH_64BIT\n",
      "  \u001b[31m   \u001b[0m In file included from src/liquidSVMmodule.cpp:37:\n",
      "  \u001b[31m   \u001b[0m In file included from src/common/liquidSVM.h:22:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/dataset.h:24:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.h:120:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.cpp:27:\n",
      "  \u001b[31m   \u001b[0m src/sources/shared/system_support/memory_allocation.h:46:10: warning: 'SYSTEM_WITH_64BIT' macro redefined [-Wmacro-redefined]\n",
      "  \u001b[31m   \u001b[0m         #define SYSTEM_WITH_64BIT\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m <command line>:2:9: note: previous definition is here\n",
      "  \u001b[31m   \u001b[0m #define SYSTEM_WITH_64BIT 1\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m In file included from src/liquidSVMmodule.cpp:37:\n",
      "  \u001b[31m   \u001b[0m In file included from src/common/liquidSVM.h:22:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/dataset.h:24:\n",
      "  \u001b[31m   \u001b[0m In file included from src/sources/shared/basic_types/sample.h:26:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:275:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__bit_reference:15:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/algorithm:653:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/functional:500:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__functional/function.h:20:\n",
      "  \u001b[31m   \u001b[0m In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/shared_ptr.h:22:\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:9: warning: destructor called on non-final 'Tsvm_decision_function' that has virtual functions but non-virtual destructor [-Wdelete-non-abstract-non-virtual-dtor]\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator_traits.h:309:13: note: in instantiation of member function 'std::allocator<Tsvm_decision_function>::destroy' requested here\n",
      "  \u001b[31m   \u001b[0m         __a.destroy(__p);\n",
      "  \u001b[31m   \u001b[0m             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:450:25: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tsvm_decision_function>>::destroy<Tsvm_decision_function, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         __alloc_traits::destroy(__alloc(), _VSTD::__to_address(--__soon_to_be_end));\n",
      "  \u001b[31m   \u001b[0m                         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:374:29: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m     void clear() _NOEXCEPT {__destruct_at_end(__begin_);}\n",
      "  \u001b[31m   \u001b[0m                             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:487:9: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::clear' requested here\n",
      "  \u001b[31m   \u001b[0m         clear();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:519:5: note: in instantiation of member function 'std::__vector_base<Tsvm_decision_function, std::allocator<Tsvm_decision_function>>::~__vector_base' requested here\n",
      "  \u001b[31m   \u001b[0m     vector() _NOEXCEPT_(is_nothrow_default_constructible<allocator_type>::value)\n",
      "  \u001b[31m   \u001b[0m     ^\n",
      "  \u001b[31m   \u001b[0m src/sources/shared/decision_function/decision_function_manager.h:64:3: note: in instantiation of member function 'std::vector<Tsvm_decision_function>::vector' requested here\n",
      "  \u001b[31m   \u001b[0m                 Tdecision_function_manager();\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m src/sources/svm/decision_function/svm_decision_function_manager.cpp:54:33: note: in instantiation of member function 'Tdecision_function_manager<Tsvm_decision_function, Tsvm_train_val_info, Tsvm_test_info>::Tdecision_function_manager' requested here\n",
      "  \u001b[31m   \u001b[0m Tsvm_decision_function_manager::Tsvm_decision_function_manager()\n",
      "  \u001b[31m   \u001b[0m                                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:15: note: qualify call to silence this warning\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:9: warning: destructor called on non-final 'Tsvm_solution' that has virtual functions but non-virtual destructor [-Wdelete-non-abstract-non-virtual-dtor]\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator_traits.h:309:13: note: in instantiation of member function 'std::allocator<Tsvm_solution>::destroy' requested here\n",
      "  \u001b[31m   \u001b[0m         __a.destroy(__p);\n",
      "  \u001b[31m   \u001b[0m             ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:450:25: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tsvm_solution>>::destroy<Tsvm_solution, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         __alloc_traits::destroy(__alloc(), _VSTD::__to_address(--__soon_to_be_end));\n",
      "  \u001b[31m   \u001b[0m                         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:857:17: note: in instantiation of member function 'std::__vector_base<Tsvm_solution, std::allocator<Tsvm_solution>>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m         __base::__destruct_at_end(__new_last);\n",
      "  \u001b[31m   \u001b[0m                 ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1477:19: note: in instantiation of member function 'std::vector<Tsvm_solution>::__destruct_at_end' requested here\n",
      "  \u001b[31m   \u001b[0m             this->__destruct_at_end(__m);\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1427:9: note: in instantiation of function template specialization 'std::vector<Tsvm_solution>::assign<Tsvm_solution *>' requested here\n",
      "  \u001b[31m   \u001b[0m         assign(__x.__begin_, __x.__end_);\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__algorithm/copy.h:35:19: note: (skipping 12 contexts in backtrace; use -ftemplate-backtrace-limit=0 to see all)\n",
      "  \u001b[31m   \u001b[0m         *__result = *__first;\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/memory:779:18: note: in instantiation of function template specialization 'std::allocator_traits<std::allocator<Tgrid<Tsvm_solution, Tsvm_train_val_info>>>::construct<Tgrid<Tsvm_solution, Tsvm_train_val_info>, const Tgrid<Tsvm_solution, Tsvm_train_val_info> &, void>' requested here\n",
      "  \u001b[31m   \u001b[0m         _Traits::construct(__a, _VSTD::__to_address(__end2 - 1),\n",
      "  \u001b[31m   \u001b[0m                  ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:976:12: note: in instantiation of function template specialization 'std::__construct_backward_with_exception_guarantees<std::allocator<Tgrid<Tsvm_solution, Tsvm_train_val_info>>, Tgrid<Tsvm_solution, Tsvm_train_val_info> *>' requested here\n",
      "  \u001b[31m   \u001b[0m     _VSTD::__construct_backward_with_exception_guarantees(this->__alloc(), this->__begin_, this->__end_, __v.__begin_);\n",
      "  \u001b[31m   \u001b[0m            ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:1117:9: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::__swap_out_circular_buffer' requested here\n",
      "  \u001b[31m   \u001b[0m         __swap_out_circular_buffer(__v);\n",
      "  \u001b[31m   \u001b[0m         ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/vector:2046:15: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::__append' requested here\n",
      "  \u001b[31m   \u001b[0m         this->__append(__sz - __cs);\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m src/sources/svm/training_validation/svm_manager.cpp:544:17: note: in instantiation of member function 'std::vector<Tgrid<Tsvm_solution, Tsvm_train_val_info>>::resize' requested here\n",
      "  \u001b[31m   \u001b[0m                 current_grids.resize(train_control.fold_control.number);\n",
      "  \u001b[31m   \u001b[0m                               ^\n",
      "  \u001b[31m   \u001b[0m /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include/c++/v1/__memory/allocator.h:159:15: note: qualify call to silence this warning\n",
      "  \u001b[31m   \u001b[0m         __p->~_Tp();\n",
      "  \u001b[31m   \u001b[0m               ^\n",
      "  \u001b[31m   \u001b[0m 3 warnings generated.\n",
      "  \u001b[31m   \u001b[0m clang++ -bundle -undefined dynamic_lookup -Wl,-rpath,/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib -Wl,-rpath,/Users/tristanvandevelde/opt/anaconda3/lib -L/Users/tristanvandevelde/opt/anaconda3/lib build/temp.macosx-10.9-x86_64-cpython-39/src/liquidSVMmodule.o -o build/lib.macosx-10.9-x86_64-cpython-39/liquidSVM.cpython-39-darwin.so -mmacosx-version-min=10.7\n",
      "  \u001b[31m   \u001b[0m clang: warning: libstdc++ is deprecated; move to libc++ with a minimum deployment target of OS X 10.9 [-Wdeprecated]\n",
      "  \u001b[31m   \u001b[0m ld: library not found for -lstdc++\n",
      "  \u001b[31m   \u001b[0m clang: error: linker command failed with exit code 1 (use -v to see invocation)\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m liquidSVM\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\u001b[?25h"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'liquidSVM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[1;32m     12\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install liquidSVM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mliquidSVM\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mCRPS\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CRPS\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'liquidSVM'"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "!pip install tensorflow_addons\n",
    "import tensorflow_addons as tfa\n",
    "!pip install liquidSVM\n",
    "from liquidSVM import *\n",
    "from CRPS import CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4119da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "hour = 17\n",
    "data = pd.read_csv(f\"../../data/final_{hour}.csv\")\n",
    "data[\"datetime\"] = pd.to_datetime(data_17[\"datetime\"])\n",
    "data.drop([\"loadFR\"], axis=1, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4259c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "# make lagged variables\n",
    "data[\"priceBE_lag1\"] = data_17[\"priceBE\"].shift(1)\n",
    "data_17[\"priceBE_lag2\"] = data_17[\"priceBE\"].shift(2)\n",
    "data_17[\"priceBE_lag3\"] = data_17[\"priceBE\"].shift(3)\n",
    "data_17[\"priceBE_lag4\"] = data_17[\"priceBE\"].shift(4)\n",
    "data_17[\"priceBE_lag5\"] = data_17[\"priceBE\"].shift(5)\n",
    "data_17.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e751d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "data_17_train = data_17[data_17[\"datetime\"].dt.year <= 2021]\n",
    "data_17_test = data_17[(data_17[\"datetime\"].dt.year == 2021) & (data_17[\"datetime\"].dt.month < 7)]\n",
    "X_train = data_17_train.drop([\"datetime\", \"priceBE\"], axis=1)\n",
    "y_train = data_17_train[\"priceBE\"]\n",
    "X_test = data_17_test.drop([\"datetime\", \"priceBE\"], axis=1)\n",
    "y_test = data_17_test[\"priceBE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a81f54",
   "metadata": {},
   "source": [
    "# Gradient Boosting (ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd24eca",
   "metadata": {},
   "source": [
    "## Normal Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5838ec2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tau \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.99\u001b[39m, \u001b[38;5;241m99\u001b[39m):\n\u001b[1;32m     14\u001b[0m     gbr \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(\n\u001b[1;32m     15\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantile\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     16\u001b[0m         alpha\u001b[38;5;241m=\u001b[39mtau, \n\u001b[1;32m     17\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_params\n\u001b[1;32m     18\u001b[0m     )\n\u001b[0;32m---> 19\u001b[0m     all_models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%1.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m alpha] \u001b[38;5;241m=\u001b[39m \u001b[43mgbr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:586\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:663\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    656\u001b[0m     old_oob_score \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    657\u001b[0m         y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    658\u001b[0m         raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    659\u001b[0m         sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# track deviance (= loss)\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:246\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    243\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    245\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 246\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    249\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    250\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    251\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m ):\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_models = {}\n",
    "common_params = dict(\n",
    "    learning_rate = 0.05,\n",
    "    n_estimators = 200,\n",
    "    max_depth = 2,\n",
    "    min_samples_leaf = 9,\n",
    "    min_samples_split = 9,\n",
    "    validation_fraction = 0.3,\n",
    "    n_iter_no_change=5,\n",
    "    tol=0.01,\n",
    "    random_state=0\n",
    ")\n",
    "for tau in np.linspace(0.01, 0.99, 99):\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        loss=\"quantile\", \n",
    "        alpha=tau, \n",
    "        **common_params\n",
    "    )\n",
    "    all_models[\"%1.2f\" % alpha] = gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8fd6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "for model in all_models:\n",
    "    predictions[model] = all_models[model].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da65bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.46844827586209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pinball_loss(y_test, predictions[\"0.05\"], alpha=0.05)\n",
    "mean_pinball_loss(y_test, predictions[\"0.50\"], alpha=0.50)\n",
    "mean_pinball_loss(y_test, predictions[\"0.95\"], alpha=0.95)\n",
    "CRPS(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da53d8d9",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7871e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8498f00a",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ac987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e53fdaa",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a92803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor = 'val_loss', \n",
    "    mode = 'min', \n",
    "    min_delta = 1,\n",
    "    patience = 50,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113a487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantileModel1():\n",
    "    # make model graph\n",
    "    model = Sequential()\n",
    "    # add 10 neurons in hidden layer with RELU activation\n",
    "    model.add(Dense(units = 10, input_dim = len(X_train.columns), activation = 'relu'))\n",
    "    # add 1 output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5af39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "154/154 [==============================] - 1s 2ms/step - loss: 115.3480 - val_loss: 105.5747\n",
      "Epoch 2/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 113.4823 - val_loss: 103.6285\n",
      "Epoch 3/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 111.4007 - val_loss: 101.4823\n",
      "Epoch 4/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 109.1252 - val_loss: 99.1537\n",
      "Epoch 5/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 106.6707 - val_loss: 96.6555\n",
      "Epoch 6/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 104.0495 - val_loss: 93.9993\n",
      "Epoch 7/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 101.2728 - val_loss: 91.1943\n",
      "Epoch 8/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 98.3484 - val_loss: 88.2480\n",
      "Epoch 9/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 95.2834 - val_loss: 85.1665\n",
      "Epoch 10/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 92.0844 - val_loss: 81.9563\n",
      "Epoch 11/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 88.7575 - val_loss: 78.6229\n",
      "Epoch 12/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 85.3063 - val_loss: 75.1696\n",
      "Epoch 13/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 81.7361 - val_loss: 71.6016\n",
      "Epoch 14/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 78.0506 - val_loss: 67.9218\n",
      "Epoch 15/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 74.2531 - val_loss: 64.1339\n",
      "Epoch 16/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 70.3470 - val_loss: 60.2410\n",
      "Epoch 17/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 66.3357 - val_loss: 56.2456\n",
      "Epoch 18/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 62.2215 - val_loss: 52.3986\n",
      "Epoch 19/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 58.1834 - val_loss: 49.3666\n",
      "Epoch 20/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 54.9791 - val_loss: 46.6572\n",
      "Epoch 21/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 52.0256 - val_loss: 44.0171\n",
      "Epoch 22/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 49.4403 - val_loss: 41.7560\n",
      "Epoch 23/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 47.4177 - val_loss: 40.0438\n",
      "Epoch 24/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 46.4492 - val_loss: 39.0899\n",
      "Epoch 25/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 46.0449 - val_loss: 38.6487\n",
      "Epoch 26/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.8284 - val_loss: 38.3432\n",
      "Epoch 27/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.6467 - val_loss: 38.0885\n",
      "Epoch 28/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.4866 - val_loss: 37.9037\n",
      "Epoch 29/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.3442 - val_loss: 37.7566\n",
      "Epoch 30/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.2143 - val_loss: 37.6214\n",
      "Epoch 31/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.1186 - val_loss: 37.5501\n",
      "Epoch 32/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.0763 - val_loss: 37.5166\n",
      "Epoch 33/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.0505 - val_loss: 37.4917\n",
      "Epoch 34/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.0330 - val_loss: 37.4629\n",
      "Epoch 35/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 45.0100 - val_loss: 37.4478\n",
      "Epoch 36/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9944 - val_loss: 37.4313\n",
      "Epoch 37/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9748 - val_loss: 37.4127\n",
      "Epoch 38/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9578 - val_loss: 37.3910\n",
      "Epoch 39/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9405 - val_loss: 37.3722\n",
      "Epoch 40/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9228 - val_loss: 37.3551\n",
      "Epoch 41/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.9063 - val_loss: 37.3392\n",
      "Epoch 42/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.8877 - val_loss: 37.3197\n",
      "Epoch 43/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.8687 - val_loss: 37.3040\n",
      "Epoch 44/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.8527 - val_loss: 37.2870\n",
      "Epoch 45/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.8355 - val_loss: 37.2683\n",
      "Epoch 46/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.8141 - val_loss: 37.2526\n",
      "Epoch 47/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.7971 - val_loss: 37.2360\n",
      "Epoch 48/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.7792 - val_loss: 37.2171\n",
      "Epoch 49/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.7596 - val_loss: 37.1993\n",
      "Epoch 50/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.7390 - val_loss: 37.1830\n",
      "Epoch 51/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.7170 - val_loss: 37.1699\n",
      "Epoch 52/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6973 - val_loss: 37.1581\n",
      "Epoch 53/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6777 - val_loss: 37.1472\n",
      "Epoch 54/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6578 - val_loss: 37.1365\n",
      "Epoch 55/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6415 - val_loss: 37.1266\n",
      "Epoch 56/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6224 - val_loss: 37.1171\n",
      "Epoch 57/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.6056 - val_loss: 37.1068\n",
      "Epoch 58/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.5880 - val_loss: 37.0964\n",
      "Epoch 59/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.5700 - val_loss: 37.0869\n",
      "Epoch 60/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.5538 - val_loss: 37.0771\n",
      "Epoch 61/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.5333 - val_loss: 37.0672\n",
      "Epoch 62/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.5183 - val_loss: 37.0563\n",
      "Epoch 63/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4955 - val_loss: 37.0457\n",
      "Epoch 64/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4816 - val_loss: 37.0358\n",
      "Epoch 65/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4605 - val_loss: 37.0235\n",
      "Epoch 66/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4422 - val_loss: 37.0126\n",
      "Epoch 67/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4202 - val_loss: 37.0023\n",
      "Epoch 68/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.4026 - val_loss: 36.9908\n",
      "Epoch 69/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3852 - val_loss: 36.9786\n",
      "Epoch 70/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3686 - val_loss: 36.9674\n",
      "Epoch 71/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3517 - val_loss: 36.9561\n",
      "Epoch 72/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3347 - val_loss: 36.9459\n",
      "Epoch 73/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3191 - val_loss: 36.9338\n",
      "Epoch 74/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.3020 - val_loss: 36.9212\n",
      "Epoch 75/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.2863 - val_loss: 36.9101\n",
      "Epoch 76/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.2679 - val_loss: 36.8983\n",
      "Epoch 77/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.2492 - val_loss: 36.8866\n",
      "Epoch 78/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.2326 - val_loss: 36.8746\n",
      "Epoch 79/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.2144 - val_loss: 36.8612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 44.1972 - val_loss: 36.8478\n",
      "Epoch 80: early stopping\n",
      "Epoch 1/500\n",
      "154/154 [==============================] - 1s 2ms/step - loss: 18970.6621 - val_loss: 18579.4512\n",
      "Epoch 2/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18904.0898 - val_loss: 18511.2109\n",
      "Epoch 3/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18830.0059 - val_loss: 18436.1797\n",
      "Epoch 4/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18749.1309 - val_loss: 18354.8652\n",
      "Epoch 5/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18662.0117 - val_loss: 18267.7070\n",
      "Epoch 6/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18569.0430 - val_loss: 18175.1855\n",
      "Epoch 7/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18470.6211 - val_loss: 18077.5195\n",
      "Epoch 8/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18366.9766 - val_loss: 17975.0391\n",
      "Epoch 9/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18258.4414 - val_loss: 17867.9863\n",
      "Epoch 10/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18145.2227 - val_loss: 17756.5527\n",
      "Epoch 11/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 18027.5410 - val_loss: 17640.9668\n",
      "Epoch 12/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17905.4609 - val_loss: 17521.2793\n",
      "Epoch 13/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17779.0059 - val_loss: 17397.6562\n",
      "Epoch 14/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17648.4277 - val_loss: 17270.1562\n",
      "Epoch 15/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17513.7969 - val_loss: 17138.9082\n",
      "Epoch 16/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17375.1484 - val_loss: 17003.9746\n",
      "Epoch 17/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17232.5000 - val_loss: 16865.4824\n",
      "Epoch 18/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 17085.9062 - val_loss: 16723.3066\n",
      "Epoch 19/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16935.6465 - val_loss: 16577.5430\n",
      "Epoch 20/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16781.6172 - val_loss: 16428.0742\n",
      "Epoch 21/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16623.9277 - val_loss: 16274.9844\n",
      "Epoch 22/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16462.4590 - val_loss: 16118.3281\n",
      "Epoch 23/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16297.2178 - val_loss: 15957.8564\n",
      "Epoch 24/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 16128.2373 - val_loss: 15793.8018\n",
      "Epoch 25/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15955.3643 - val_loss: 15626.0137\n",
      "Epoch 26/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15778.9863 - val_loss: 15454.4580\n",
      "Epoch 27/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15599.1553 - val_loss: 15279.1748\n",
      "Epoch 28/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15415.8184 - val_loss: 15100.0117\n",
      "Epoch 29/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15228.9248 - val_loss: 14917.3506\n",
      "Epoch 30/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 15038.1670 - val_loss: 14730.6748\n",
      "Epoch 31/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 14843.4678 - val_loss: 14540.3740\n",
      "Epoch 32/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 14645.0547 - val_loss: 14346.2627\n",
      "Epoch 33/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 14442.6162 - val_loss: 14148.3291\n",
      "Epoch 34/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 14236.3730 - val_loss: 13946.6348\n",
      "Epoch 35/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 14026.3232 - val_loss: 13741.2490\n",
      "Epoch 36/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 13812.5420 - val_loss: 13531.8750\n",
      "Epoch 37/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 13594.7842 - val_loss: 13318.4805\n",
      "Epoch 38/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 13372.8711 - val_loss: 13101.0049\n",
      "Epoch 39/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 13146.8730 - val_loss: 12879.4531\n",
      "Epoch 40/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 12916.7246 - val_loss: 12653.7549\n",
      "Epoch 41/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 12682.4658 - val_loss: 12423.9932\n",
      "Epoch 42/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 12443.9717 - val_loss: 12189.8906\n",
      "Epoch 43/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 12201.0078 - val_loss: 11951.3564\n",
      "Epoch 44/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 11953.3057 - val_loss: 11707.9570\n",
      "Epoch 45/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 11700.2393 - val_loss: 11459.1123\n",
      "Epoch 46/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 11441.1650 - val_loss: 11204.1934\n",
      "Epoch 47/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 11175.5078 - val_loss: 10942.5576\n",
      "Epoch 48/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 10902.6455 - val_loss: 10673.6270\n",
      "Epoch 49/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 10621.9004 - val_loss: 10396.6309\n",
      "Epoch 50/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 10332.4023 - val_loss: 10110.7568\n",
      "Epoch 51/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 10033.3330 - val_loss: 9815.1533\n",
      "Epoch 52/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 9723.7812 - val_loss: 9508.8232\n",
      "Epoch 53/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 9402.5967 - val_loss: 9190.6660\n",
      "Epoch 54/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 9068.6797 - val_loss: 8859.4883\n",
      "Epoch 55/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 8720.6953 - val_loss: 8513.9346\n",
      "Epoch 56/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 8357.2227 - val_loss: 8152.5396\n",
      "Epoch 57/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 7976.5645 - val_loss: 7773.5610\n",
      "Epoch 58/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 7576.9590 - val_loss: 7375.1509\n",
      "Epoch 59/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 7156.3848 - val_loss: 6955.1997\n",
      "Epoch 60/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 6712.5049 - val_loss: 6511.3345\n",
      "Epoch 61/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 6242.7993 - val_loss: 6040.9746\n",
      "Epoch 62/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 5744.4731 - val_loss: 5541.1641\n",
      "Epoch 63/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 5214.2876 - val_loss: 5008.5508\n",
      "Epoch 64/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 4648.5884 - val_loss: 4439.3750\n",
      "Epoch 65/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 4043.4365 - val_loss: 3829.4863\n",
      "Epoch 66/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 3394.1619 - val_loss: 3174.1895\n",
      "Epoch 67/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 2696.6655 - val_loss: 2471.1426\n",
      "Epoch 68/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 1957.9785 - val_loss: 1741.7754\n",
      "Epoch 69/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 1228.1730 - val_loss: 1092.9595\n",
      "Epoch 70/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 660.2067 - val_loss: 662.1689\n",
      "Epoch 71/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 343.0451 - val_loss: 416.3319\n",
      "Epoch 72/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 199.9392 - val_loss: 287.2930\n",
      "Epoch 73/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 136.7766 - val_loss: 218.8361\n",
      "Epoch 74/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 107.1865 - val_loss: 178.6344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 90.9094 - val_loss: 152.8389\n",
      "Epoch 76/500\n",
      "154/154 [==============================] - 0s 1ms/step - loss: 80.5082 - val_loss: 134.1165\n",
      "Epoch 77/500\n",
      "126/154 [=======================>......] - ETA: 0s - loss: 76.5845"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m quantileModel1()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39mfunctools\u001b[38;5;241m.\u001b[39mpartial(tfa\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mpinball_loss, tau\u001b[38;5;241m=\u001b[39mtau),\n\u001b[1;32m      5\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madadelta\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m all_models[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%1.2f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m tau] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1681\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1682\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m }\n\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2038\u001b[0m ):\n\u001b[1;32m   2039\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2042\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mconcrete_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:338\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;66;03m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# only active captures should be saved.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m lookup_func_key, _ \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_cache_key((args, kwargs),\n\u001b[1;32m    337\u001b[0m                                                      captures)\n\u001b[0;32m--> 338\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlookup_func_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m concrete_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    340\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_function, filtered_flat_args\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_cache.py:119\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, key, use_function_subtyping)\u001b[0m\n\u001b[1;32m    117\u001b[0m dispatch_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_table\u001b[38;5;241m.\u001b[39mdispatch(key)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_primary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdispatch_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_cache.py:77\u001b[0m, in \u001b[0;36mFunctionCacheKey.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:246\u001b[0m, in \u001b[0;36mFunctionType.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m      \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:106\u001b[0m, in \u001b[0;36mParameter.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 106\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkind, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptional, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:62\u001b[0m, in \u001b[0;36mParameter.type_constraint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtype_constraint\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[trace\u001b[38;5;241m.\u001b[39mTraceType]:\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;124;03m\"\"\"A supertype that the parameter's type must subtype for validity.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotation \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotation\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/inspect.py:2558\u001b[0m, in \u001b[0;36mParameter.annotation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mannotation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 2558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_annotation\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for tau in np.linspace(0.01, 0.99, 99):\n",
    "    model = quantileModel1()\n",
    "    model.compile(\n",
    "        loss=functools.partial(tfa.losses.pinball_loss, tau=tau),\n",
    "        optimizer = \"adadelta\"\n",
    "    )\n",
    "    all_models[\"%1.2f\" % tau] = model.fit(\n",
    "        X_train, y_train, \n",
    "        validation_split = 0.3,\n",
    "        epochs = 500, \n",
    "        batch_size = 32,\n",
    "        verbose = 1,\n",
    "        callbacks = [es]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bb615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extension: use the functional API in case of more complex structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648ebc7",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c8c8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e77976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
